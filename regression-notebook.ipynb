{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stažení a instalace knihoven, které budeme používat\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import knihoven, které budeme používat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regrese\n",
    "\n",
    "#### Autoři:\n",
    "* [Martin Vlach](mailto:xvlach@mendelu.cz)\n",
    "* [Jakub Dolejší](mailto:xdolejsi@mendelu.cz)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regrese v různých vědních odvětvích\n",
    "- **Lékařství** - *regrese nemoci*\n",
    "- **Právo** - *regresy*\n",
    "- **Filozofie** - *nekonečný regres*\n",
    "- **Softwarové inženýrství** - *regresní testování*\n",
    "- <span style=\"color:#eb4034\">**Statistika** - *regresivní analýza*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Regresivní analýza\n",
    "* Jedna z nejpoužívanějších statistických metod.\n",
    "* Existuje značné množství variant, přičemž každá je vhodná na jiný typ problému.\n",
    "\n",
    "</br>\n",
    "\n",
    "* ***Definice*** - *Označení statistických metod, které souží k odhadu jisté náhodné veličiny na základě znalosti jedné či více jiných veličin. Cílem regresní analýzy je popsat tuto závislost pomocí vhodného modelu.*\n",
    "\n",
    "    * ***Závislá proměnná*** - *Parametr, jehož hodnotu zkoumáme/hledáme.*\n",
    "    * ***Nezávislá proměnná*** - *Parametr, jehož hodnota je nám známa. S využítím těchto hodnot je hledána hodnota závislé proměnné. Tyto hodnoty se často označují jako regresory*\n",
    "\n",
    "#### Dělení regresivních modelů\n",
    "* Diskrétní hodnoty proměnných **x** Spojité hodnoty proměnných **x** Kombinace\n",
    "* Jednoduchá **x** Vícenásobná\n",
    "* Lineární **x** Nelineární závislost\n",
    "---\n",
    "\n",
    "### Co to regrese vůbec je?\n",
    "Regrese je obecně aparát sloužící k odhadu vztahu mezi závislou a nezávislou proměnnou.\n",
    "Regresi si lze představit jak funkci, která má obecně N vstupů a jeden výstup. Každý jeden vstupní\n",
    "parametr představuej nezávislou proměnnou, přičemž výstup je proměnná závislá na všech vstupech.\n",
    "\n",
    "\n",
    "![image info](images/regression.jpg)\n",
    "\n",
    "\n",
    "### Jaké jsou její typy\n",
    "\n",
    "Jak již bylo zmíněno, regresi lze rozdělit do několika tříd dle jejího využití. Regrese je jedním\n",
    " ze základních metod <i>učení s učitelem</i>. Pravděpodobně nejčastěji použitým typem regrese je lineární regrese. Jejím zobecněním následně je vícenásobná lineární\n",
    "regrese. Dále existuje logistická regrese, která slouží ke klasifikaci, tj. zařazení vstupní\n",
    "hodnoty do některé ze tříd s určitou pravděpodobností. Pokročilým typem regrese je\n",
    "<i>Support Vector Machine</i>, který slouží i k klasifikaci.\n",
    "\n",
    "#### Lineární regrese\n",
    "Lineární regrese je, jak již bylo avizovno, speciálním případem obecného regresního modelu.\n",
    "Lineární regrese ma na svém vstupu nezávislou proměnnou, např. plocha pozemku, a na svém\n",
    "výstupu závislou proměnnou, např. cena. Cílem lineární regrese ja najít takovou lineární funkci,\n",
    "která bude co nejlépe aproximovat daný soubor dat. Obecným předpokladem pro lineární regrese\n",
    "je že data mají lineární trend, tj. je možné je proložit lineární přímkou.\n",
    "\n",
    "Naším úkolem je naučit se lineární funkci tj. najít vhodné parametry $ w_{1} $ a $w_{0}$.\n",
    "\n",
    " $ y = f(x) = w_{1}x + w_{0} $\n",
    "\n",
    "Dále předpokládáme, že skutečné hodnoty z datasetu jsou zatíženy chybou.\n",
    "\n",
    "$ t = y_{n} + \\epsilon _{n}  $, kde $\\epsilon$ je Gaussovský šum\n",
    "\n",
    "To znamená, že hodnoty z našeho datasetu neleží přímo na lineární přímce, ale jsou rozptýleny kolem ní, a to\n",
    "dle normálního rozložení $ N(\\mu ; 0, \\sigma^2) $, přičemž střední hodnota je nulová a rozptyl se ja závislý\n",
    "na datasetu.\n",
    "\n",
    "\n",
    "![image info](images/error.png)\n",
    "\n",
    "Z obrázku vidíme, že každý vstup z datasetu je zatížen nějakou chybou (pokud by nebyl, všechny\n",
    "data by ležela na lineární přímce). Zde lze postupovat několika způsoby, nicméně v každém případě se budeme snažit nalézt parametry\n",
    "lineární přímky tak, aby výsledná chyba byla co nejmenší\n",
    "\n",
    "<ol>\n",
    "<li><b>Pomocí metody nejmenších čtverců</b></li>\n",
    " Nejdříve je nutné najít chybu, což lze udělat tak, že si vypočteme druhou mocninu všech chyb, tedy\n",
    " čtverce, a sečteme je.\n",
    "\n",
    " $ E(w_{0}, w_{1}) = \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 = \\sum \\limits _{i=1} ^N (t_{n} - w_{1}x + w_{0})^2$\n",
    "\n",
    "Pro každý vzorek z datasetu vezmeme jeho skutečnou hodnotu, odečteme od něj predikovanou\n",
    "hodnotu, a získame chybu konkrétního vzorku, kterou následně umocníme na druhou.\n",
    "Tyto chyby sečteme a získáme celkovou chybu. Nyní je na místě si položit otázku, proč je nutné\n",
    "provést umocnění. Odpoveď je taková, že kdyby jeden vzorek obsahoval chybu +0.5 a druhý vzorek\n",
    "-0.5, tyto dvě hodnoty by se nám díky sumě odečetly, a celková chyba by byla 0, což ovšem není pravda,\n",
    "protože by hodnoty vzorů musely ležet přímo na přímce. Tam ale neleží, což víme díky tomu, že každý\n",
    "oba vzorky jsou zatíženy nějakou chybou.\n",
    "\n",
    "Jako další vhodná operace se nabízí absolutní hodnota. Ta nám již odstraní případné\n",
    "odečtení chyby, nicméně jak posléze zjistíme, bude potřeba provést parciální derivace. Derivace\n",
    "mocniny je ovšem daleko jednoduší než derivace absolutní hodnoty. Dále, kvadratická chyba nám zajistí,\n",
    "že se hodnoty datasetu budou chovat, jako by byly rozmístěny dle normálního rozložení\n",
    "se středem v predikované hodnotě lineární funkce, což je náš předpoklad. Konečně, kvadratická\n",
    "funkce má pouze jedno lokální, resp. globální minimum.\n",
    "\n",
    "(Poznámka: Pokud bychom chtěli použít absolutní hodnotu, pracovali bychom s Lappplaceovým rozložení)\n",
    "\n",
    "\n",
    "Jak již bylo naznačeno, naším úkolem je nalézt globální minimmum z funkce $E(w_{0}, w_{1})$, tj.\n",
    "nalézt takové parametry  $w_{0}, w_{1}$, pro které bude bude suma všech čtverců chyb nejmenší.\n",
    "Z matematické analýzy víme, že se pokud hledáme globální minimum, tak je nutné nalézt\n",
    "parciální derivace funkce pode $w_{0}$ a $w_{1}$ a následně sestavit soustavu dvou rovnic\n",
    "o dovu neznámých.\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = 0 $\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = 0 $\n",
    "\n",
    "Vypočteme derivaci podle $w_{0}$ a vypočteme; analogicky určítem i $w_{1}$ .\n",
    "\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = ...  -2 (\\sum_{i=0}^N t_{i} - w_{0}(n+1) - w_{1} \\sum_{i=0}^N x_{i})$\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = \\sum_{i=0}^N 2(t_{i} - w_{0} - w_{1}x_{i})(-x_{i}) = -2 \\sum_{i=0}^N (t_{i}x_{i} - w_{0}x_{i} - w_{1}x_{i}^2)  $\n",
    "\n",
    "Výsledky paricálních derivací nyní dosadit do soustavy rovnic, a máme výslednou,\n",
    "tzn. <b>normální rovnici</b>.\n",
    "\n",
    "$ w_{0}(n+1) + w_{1}\\sum_{i=0}^N x_{i} = \\sum_{i=0}^N t_{i} $\n",
    "\n",
    "$ w_{0} \\sum_{i=0}^N x_{i} + w_{1} \\sum_{i=0}^N x_{i}^2 = \\sum_{i=0}^N x_{i}t_{i}$\n",
    "\n",
    "\n",
    "<li><b>Pomocí gradientu</b></li>\n",
    "\n",
    "Častější je ovšem využití gradientu. Gradient je vektor, který nám ukazuje, jakým směrem je\n",
    "derivace největší, tj. jakým směrem přímka nejrychleji stoupá. Pokud tento vektor otočíme o 90 stupňů,\n",
    "bude ukazovat kudy naše funkce nejrychleji klesá, a to je přesně co chceme. Z úvodu víme, že\n",
    "budeme hledat minimum v kvadratické funkci, která má minimum pouze jedno. To znamená, že se\n",
    "nemusíme obávat, že by jsme uvázli v lokálním minimu.\n",
    "\n",
    "Jedím z algoritmů pro nalezení takovéhoto minima je <i>Steepest Gradient Descent</i>. Tento\n",
    "algoritmus postupuje po krocích zvolené délky, a pro každý krok počítá nový gradient, tj. nový směr,\n",
    "kterým má postupovat. A kdy že se má alogritmus zastavit? Opět víme, že pokud je derivace\n",
    "nulová, může to znamenat hned několik věcí. Může se zde nacházet bod podezřelý z extrému, inflexní bod\n",
    "či lokální minimum. V každém případě to ovšem znamená, že daná funkce je zde\n",
    "rovnoběžná s osou <i>x</i>, a to implikuje jediné; našli jsme minimum funkce.\n",
    "\n",
    "Nevýhodou tohoto algoritmu je skutečnost, že pro výpočet každého gradientu je nutné projít\n",
    "celý dataset. Pokud náš dataset obsahuje 100 milionů záznamů, může to být trošku problém. V tomto\n",
    "případě lze zvolit jinou metodu, kupříkladu <i>Stochastic Gradient Descent</i>. Tato metoda počítá\n",
    "gradient z jednoho, náhodně výbraného vzorku. Její postup samozřejmě není tolik přímočarý\n",
    "jako v případě  <i>Steepest Gradient Descent</i>, ovšem není tolik náročný.\n",
    "\n",
    "\n",
    "<li><b>Pomocí lineární algebry</b></li>\n",
    "\n",
    "Posledním, ovšem nejvíce sofistikovaným způsobem je využít operací nad maticemi a vektory, pomocí\n",
    "kterých lze dojít k výsledku během jednoho kroku. To znamená, že nad naší vstupní rovnicí provedeme\n",
    "několik maticových operací, jejiž výsledkem budou optimální parametry $w_{0}$ a $w_{1}$.\n",
    "\n",
    "Nejdříve začneme tím, že si rovnici můžeme přepsat do skalárního součinu.\n",
    "\n",
    "$y = w_{1}x + w_{0} =  \\hat x^Tw $ , kde\n",
    "\n",
    "$ \\mathbf{\\hat x}= \\begin{bmatrix}1 \\\\\n",
    "x\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$ \\mathbf{w}= \\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Můžeme něco takového udělat? Samozřejmě, protože násobíme transponovaný sloupcpvý vektor, tj. řádkový\n",
    "s sloupcovým vektorem. Tzn. máme operaci\n",
    "$\\begin{bmatrix}1 \\space\n",
    "x\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix} = 1 w_{0} + xw_{1} = w_{1}x + w_{0} = y$\n",
    "\n",
    "\n",
    "Vzorec pro objektivní funkci je opět stejný, nicméně pro další odovozování použijeme\n",
    "notaci skalárního součinu a přidáme vynásobení konstantou. Tato konstanta nás nijak netrápí,\n",
    "na nalezení minima či maxima to nemá žádný vliv.\n",
    "\n",
    "$ E(w0, w1) = \\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 =\\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w} )^2$\n",
    "\n",
    "Nyní si naši funkci dvou proměnných $ E(w0, w1)$ můžeme přepsat jako funkci\n",
    " vektoru $ E( \\mathbf{w})$. Nebude nyní derivovat podle dvou proměnných, ale podle vektoru.\n",
    " Výstupem této funkce je opět nám již známý gradient.\n",
    "\n",
    "\n",
    "\n",
    " $ \\frac{\\partial}{\\partial\\mathbf{w}}E(\\mathbf{w}) =\n",
    " \\frac{\\partial}{\\partial\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    " $\n",
    "\n",
    "\n",
    " Poznámka: Gradient se dá ekvivalentně zapsat jako\n",
    " $ \\triangledown_{\\mathbf{w}} E(\\mathbf{w}) =\n",
    " \\frac{\\partial E (\\mathbf{w})}{\\partial \\mathbf{w}} =\n",
    "  \\begin{bmatrix} \\frac{\\partial E (\\mathbf{w})}{\\partial w_{0}} \\\\\n",
    "    \\frac{\\partial E (\\mathbf{w})}{\\partial w_{1}}\n",
    "    \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "\n",
    "V následujícím kroku jsme si akorát konstantu vytkly před sumu, s tím že derivace sumy je suma derivací.\n",
    "\n",
    "$\n",
    "= \\frac{1}{2}  \\sum_{n=1}^N \\frac{\\partial}{\\partial\\mathbf{w}} (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    "$\n",
    "\n",
    "Nyní naši objektivní funkci zderivujeme podle vektoru $ \\mathbf{w}$. Funkci derviuje klasicky jako složenou funkci,\n",
    "tj. druhou mocninu dám před funkci, zde se nám krásně vykrátí s naší konstantou a následně vynásobíme\n",
    "vnitřní složkou funkce\n",
    "\n",
    "\n",
    "$\n",
    "= \\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w}) \\frac{\\partial}{\\partial\\mathbf{w}}\n",
    "\\color{#f05454}{(t_{n} - \\hat x_{n}^T \\mathbf{w})}\n",
    "$\n",
    "\n",
    "\n",
    " Nyní nám zbýva zderivovat právě onu vnitřní složku funkce (červená část ). Když se na tuto část podíváme,\n",
    " zjistíme že první složka závorky  ($t_{n}$) je konstanta, tzn. ať už budeme derivovat podle čehokoliv,\n",
    " vždy to bude 0. Nás tedy bude zajímat druhá část závorky, kde je skalární součin vektoru, který budeme\n",
    " chtít derivovat podle vektoru $\\mathbf{w}$, což je vlastně parciální derivace podle\n",
    " jeho složek, tj. $w_{0}$ a $w_{1}$.\n",
    "\n",
    " Nyní si to více rozepíšeme. Potřebujeme tedy vypočítat derivaci druhé části červené závorky, což je:\n",
    "\n",
    "\n",
    " $\n",
    "  \\frac{\\partial}{\\partial \\mathbf{w}} \\mathbf{\\hat x}_{n}^T \\mathbf{w} =\n",
    "  $\n",
    "\n",
    "  $ =\\frac{\\partial}{\\partial \\mathbf{w}} \\begin{bmatrix}w_{0}x_{0} + \\space\n",
    "w_{1}x_{1}\n",
    "\\end{bmatrix}\n",
    " $\n",
    "\n",
    " Nyní máme rozepsaný skalární součin vektorů. Když ho zderivujeme podle $w_{0}$, dostaname $x_{0}$,\n",
    " když ho zderivujeme podle $w_{1}$, dostaneme $x_{1}$. To znamená, že derivace celé závorky je\n",
    " $\\mathbf{\\hat x}$, takže to tak můžeme přepsat i v červené části rovnice.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w})\n",
    "\\color{#f05454}{\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "\n",
    "Aktuálně máme furt stejnou rovnici, která nám počítá gradient, akorát mírně upravenou. Nyní celou závorku\n",
    "vynásobíme vektorem $\\mathbf{\\hat x}$ (červeně), takže nám vzniknou dvě sumy. Dále, výraz položíme rovno\n",
    "0, protože nás samozřejmě zajímá, kde je gradient rovný 0, tzn. kde je minimum funkce.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N t_{n}\n",
    "\\mathbf{\\hat x_{n}} - \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{ \\hat x}_{n}^T \\mathbf{w} = 0\n",
    "$\n",
    "\n",
    "Naším posledním větším krokem bude vytknout si $\\mathbf{w}$, což je vektor koeficientů $w_{0}$ a\n",
    "$w_{1}$. Nyní si první sumu si převedeme na pravou stranu rovnice.\n",
    "\n",
    "$\n",
    "\\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n} \\mathbf{w} = \\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}\n",
    "$\n",
    "\n",
    "\n",
    "Dále můžeme z levé strany rovnice oddělit $\\mathbf{w}$ od zbytku výrazu, protože $\\mathbf{w}$ nemá index sumy,\n",
    "tzn. na ní nezáleží.\n",
    "\n",
    "$\n",
    "\\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})}  \\mathbf{w} = \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "Nyní chcem dostat samotné $\\mathbf{w}$. To znamená, že celou rovnici musíme podělit červeným výrazem. Když si\n",
    "uvědomíme, že červený výraz je ve skutečnosti násobení sloupcového vektoru řádkovým, tzn. výsledek je matice\n",
    "2x2, tak zjistíme, že potřebujeme celou rovnici podělit maticí 2x2. Toho docílíme tak, že zleva k celé rovnici\n",
    "přínásobíme její inverzní matici. Na levé straně rovnice tedy zůstane samotné $\\mathbf{w}$, protože pokud\n",
    "matici vynásobíme její inverzní maticí, dostaneme jednotkovou matici.\n",
    "\n",
    "$\n",
    "\\mathbf{w} = \\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})^{-1}} \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "A máme řešení! Pokud hodnoty vektoru $\\mathbf{w}$, tj. $w_{0}$ a $w_{1}$ nastavíme na hodnoty, které nám vrátí\n",
    "naše pravá strana rovnice, máme naše hledané parametry.\n",
    "\n",
    "</ol>\n",
    "\n",
    "#### Polynomiální regrese\n",
    "\n",
    "Nyní si můžeme říct, že né všechny data se dají napasovat na lineární funkci, tzn. někdy je třeba\n",
    "aproximovat data polynomem. My se nyní naučíme aproximovat jakkoliv složitou funkci. Abychom\n",
    "tuto funkci ovšem mohli vytvořit, je nutné ji poskládat z jednodušších funkcí. Tyto funkce mohou\n",
    "být kupříkladu polynomy, obecně vzato to mohou být jakkékoliv nelineární funkce. Uvažujme příklad\n",
    "polynomů $x^0, x^1, x^2, x^3$. Pokud k těmto funkcím přidáme nějaké koeficienty a začneme je\n",
    "lineárně kombinovat, můžeme dostat libovonlný polynom nejvýše N-tého stupně, přičemž N je počet členů.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineární regrese\n",
    "\n",
    "#### Jednoduchá lineární regrese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahující záznamy o pohlaví-výška-váha\n",
    "Zdroj: https://www.kaggle.com/mustafaali96/weight-height\n",
    "\"\"\"\n",
    "\n",
    "wh_df = pd.read_csv('data/weight-height.csv')\n",
    "wh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Příklad jednoduché regresivní analýzy (pouze jeden regres)\n",
    "Z tohoto důvodu budeme zkoumat pouze muže a sloupec pohlaví můžeme ignorovat.\n",
    "Dále si převedeme hodnoty z datasetu na metrické jednotky, neboť jsou uvedeny v imperiálních hodnotách.\n",
    "\"\"\"\n",
    "\n",
    "# 1 palec = 2,54 cm\n",
    "height_constant = 2.54\n",
    "\n",
    "# 1 libra = 0,45359237 kg\n",
    "weight_constant = 0.4535923\n",
    "\n",
    "males_only_df = (wh_df[(wh_df.Gender == 'Male')]).drop('Gender',1) #\n",
    "males_only_df.Height *= height_constant\n",
    "males_only_df.Weight *= weight_constant\n",
    "males_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males_only_df.plot.scatter(x=\"Height\", y=\"Weight\", color='b', title='Height x Weight [Males only]', s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ověření lineární korelační závislosti\n",
    "\n",
    "p - Pearsonův korelační koeficient měří sílu lineární závislosti mezi dvěma veličinami.\n",
    "\n",
    "OTÁZKA - Jakých hodnot může p nabývat?\n",
    "\"\"\"\n",
    "x = males_only_df.Height\n",
    "y = males_only_df.Weight\n",
    "p = stats.pearsonr(x, y)\n",
    "print(f\"Hodnota Pearsonova korelačního koeficientu: {p[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape((-1, 1)), y)\n",
    "print(model.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"blue\", s=2)\n",
    "plt.plot(x, model.predict(x.values.reshape((-1, 1))), color = \"red\")\n",
    "plt.title(\"Male weight prediction\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = input('Zadejte vaši výšku: ')\n",
    "weight_predict = model.predict(np.array(float(input_height)).reshape((-1, 1)))[0]\n",
    "print(f\"Predikovaná váha dle jednoduché lineární regresivní analýzy: {np.round(weight_predict, 2)}kg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vícenásobná lineární regrese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahující záznamy o parametrech prodaných aut\n",
    "Zdroj: https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho\n",
    "\"\"\"\n",
    "\n",
    "#MPG = Počet ujetých mil na jeden Galon (3,785 litru) -> Vyšší je lepší\n",
    "toLitres = lambda x : 235.214583 / x\n",
    "\n",
    "column_names = ['mpg', 'horsepower', 'weight', 'acceleration','displacement']\n",
    "\n",
    "cubic_inch_constant = 16.387064\n",
    "\n",
    "cars_df = pd.read_csv('data/auto-mpg.csv', usecols=column_names, na_values='?')\n",
    "cars_df.weight *= weight_constant\n",
    "cars_df.displacement *= cubic_inch_constant\n",
    "cars_df.dropna()\n",
    "\n",
    "cars_df.horsepower =  cars_df.horsepower.astype('float')\n",
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1 = stats.pearsonr(cars_df['mpg'], cars_df['horsepower'])[0]\n",
    "p2 = stats.pearsonr(cars_df['mpg'], cars_df['weight'])[0]\n",
    "p3 = stats.pearsonr(cars_df['mpg'], cars_df['acceleration'])[0]\n",
    "p4 = stats.pearsonr(cars_df['mpg'], cars_df['displacement'])[0]\n",
    "\n",
    "print(f\"Míra lineární závislosti spotřeba x počet koní: {p1}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x hmotnost: {p2}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zrychlení: {p3}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zdvihový objem: {p4}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.plot.scatter(x='horsepower', y='mpg', color='r', title='MPG x Horsepower')\n",
    "cars_df.plot.scatter(x='weight', y='mpg', color='b', title='MPG x Weight')\n",
    "cars_df.plot.scatter(x='acceleration', y='mpg', color='g', title='MPG x Acceleration')\n",
    "cars_df.plot.scatter(x='displacement', y='mpg', color='m', title='MPG x Zdvihový objem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "second_model_x = cars_df[['horsepower', 'acceleration', 'weight', 'displacement']]\n",
    "second_model_y = cars_df['mpg']\n",
    "\n",
    "# V datasetu jsou často výkonná auta u sebe, proto použijeme určitý pseudonáhodný pick\n",
    "seed = random.randint(0, 1000)\n",
    "\n",
    "second_model_x_train, second_model_x_test, \\\n",
    "second_model_y_train, second_model_y_test = train_test_split\\\n",
    "(second_model_x, second_model_y,test_size=0.25,random_state=seed)\n",
    "\n",
    "second_model.fit(second_model_x_train, second_model_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST přesnosti modelu\n",
    "\n",
    "accuracy = np.round(second_model.score(second_model_x_test, second_model_y_test), 4) * 100\n",
    "print(f'Přesnost modelu: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikce spotřeby jiného staršího vozidla - použijeme Škodu 120\n",
    "# Zdroj: http://skodaps.wz.cz/S105-136_technicke_1.php\n",
    "\n",
    "# Nutné brát v potaz, že mnoho aut v datasetu jsou auta americká\n",
    "\n",
    "s120_horsepower = 53.0\n",
    "s120_acceleration = 20.0\n",
    "s120_weight = 890.0\n",
    "s120_displacement = 1147.0\n",
    "\n",
    "s120_stats = np.array([s120_horsepower,s120_acceleration, s120_weight, s120_displacement])\n",
    "result = second_model.predict(s120_stats.reshape(1, -1))[0]\n",
    "print(\"Predikovaná spotřeba vozu Škoda 120 pomocí vícenásobné lineární regresivní analýzy: {}l/100km.\".\\\n",
    "      format(np.round(toLitres(result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stažení a instalace knihoven, které budeme používat\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import knihoven, které budeme používat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regrese\n",
    "\n",
    "#### Autoři:\n",
    "* [Martin Vlach](mailto:xvlach@mendelu.cz)\n",
    "* [Jakub Dolejší](mailto:xdolejsi@mendelu.cz)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regrese v různých vědních odvětvích\n",
    "- **Lékařství** - *regrese nemoci*\n",
    "- **Právo** - *regresy*\n",
    "- **Filozofie** - *nekonečný regres*\n",
    "- **Softwarové inženýrství** - *regresní testování*\n",
    "- <span style=\"color:#eb4034\">**Statistika** - *regresivní analýza*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Regresivní analýza\n",
    "* Jedna z nejpoužívanějších statistických metod.\n",
    "* Existuje značné množství variant, přičemž každá je vhodná na jiný typ problému.\n",
    "\n",
    "</br>\n",
    "\n",
    "* ***Definice*** - *Označení statistických metod, které souží k odhadu jisté náhodné veličiny na základě znalosti jedné či více jiných veličin. Cílem regresní analýzy je popsat tuto závislost pomocí vhodného modelu.*\n",
    "\n",
    "    * ***Závislá proměnná*** - *Parametr, jehož hodnotu zkoumáme/hledáme.*\n",
    "    * ***Nezávislá proměnná*** - *Parametr, jehož hodnota je nám známa. S využítím těchto hodnot je hledána hodnota závislé proměnné. Tyto hodnoty se často označují jako regresory*\n",
    "\n",
    "\n",
    "\n",
    "### Co to regrese vůbec je?\n",
    "Regrese je obecně aparát sloužící k odhadu vztahu mezi závislou a nezávislou proměnnou.\n",
    "Regresi si lze představit jak funkci, která má obecně N vstupů a jeden výstup. Každý jeden vstupní\n",
    "parametr představuej nezávislou proměnnou, přičemž výstup je proměnná závislá na všech vstupech.\n",
    "\n",
    "\n",
    "<img src=\"images/regression.jpg\" alt=\"drawing\" width=\"350\"/>\n",
    "\n",
    "### Jaké jsou její typy\n",
    "\n",
    "\n",
    "\n",
    "Jak již bylo zmíněno, regresi lze rozdělit do několika tříd dle jejího využití. Regrese je jedním\n",
    " ze základních metod <i>učení s učitelem</i>. Pravděpodobně nejčastěji použitým typem regrese je lineární regrese. Jejím zobecněním následně je vícenásobná lineární\n",
    "regrese. Pro určité typy vztahů je vhodné použít regresi polynomiální. Dále existuje logistická regrese, která slouží ke klasifikaci, tj. zařazení vstupní\n",
    "hodnoty do některé ze tříd s určitou pravděpodobností. Pokročilým typem regrese je\n",
    "<i>Support Vector Machine</i>, který slouží i k klasifikaci.\n",
    "\n",
    "#### Dělení regresivních modelů\n",
    "* Diskrétní hodnoty proměnných **x** Spojité hodnoty proměnných **x** Kombinace\n",
    "* Jednoduchá **x** Vícenásobná\n",
    "* Lineární **x** Nelineární závislost\n",
    "---\n",
    "\n",
    "#### Lineární regrese\n",
    "Lineární regrese je, jak již bylo avizovno, speciálním případem obecného regresního modelu.\n",
    "Lineární regrese ma na svém vstupu nezávislou proměnnou, např. plocha pozemku, a na svém\n",
    "výstupu závislou proměnnou, např. cena. Cílem lineární regrese ja najít takovou lineární funkci,\n",
    "která bude co nejlépe aproximovat daný soubor dat. Obecným předpokladem pro lineární regrese\n",
    "je že data mají lineární trend, tj. je možné je proložit lineární přímkou.\n",
    "\n",
    "Naším úkolem je naučit se lineární funkci tj. najít vhodné parametry $ w_{1} $ a $w_{0}$.\n",
    "\n",
    " $ y = f(x) = w_{1}x + w_{0} $\n",
    "\n",
    "Dále předpokládáme, že skutečné hodnoty z datasetu jsou zatíženy chybou.\n",
    "\n",
    "$ t = y_{n} + \\epsilon _{n}  $, kde $\\epsilon$ je Gaussovský šum\n",
    "\n",
    "To znamená, že hodnoty z našeho datasetu neleží přímo na lineární přímce, ale jsou rozptýleny kolem ní, a to\n",
    "dle normálního rozložení $ N(\\mu ; 0, \\sigma^2) $, přičemž střední hodnota je nulová a rozptyl se ja závislý\n",
    "na datasetu.\n",
    "\n",
    "\n",
    "![image info](images/error.png)\n",
    "\n",
    "Z obrázku vidíme, že každý vstup z datasetu je zatížen nějakou chybou (pokud by nebyl, všechny\n",
    "data by ležela na lineární přímce). Zde lze postupovat několika způsoby, nicméně v každém případě se budeme snažit nalézt parametry\n",
    "lineární přímky tak, aby výsledná chyba byla co nejmenší\n",
    "\n",
    "<ol>\n",
    "<li><b>Pomocí metody nejmenších čtverců</b></li>\n",
    " Nejdříve je nutné najít chybu, což lze udělat tak, že si vypočteme druhou mocninu všech chyb, tedy\n",
    " čtverce, a sečteme je.\n",
    "\n",
    " $ E(w_{0}, w_{1}) = \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 = \\sum \\limits _{i=1} ^N (t_{n} - w_{1}x + w_{0})^2$\n",
    "\n",
    "Pro každý vzorek z datasetu vezmeme jeho skutečnou hodnotu, odečteme od něj predikovanou\n",
    "hodnotu, a získame chybu konkrétního vzorku, kterou následně umocníme na druhou.\n",
    "Tyto chyby sečteme a získáme celkovou chybu. Nyní je na místě si položit otázku, proč je nutné\n",
    "provést umocnění. Odpoveď je taková, že kdyby jeden vzorek obsahoval chybu +0.5 a druhý vzorek\n",
    "-0.5, tyto dvě hodnoty by se nám díky sumě odečetly, a celková chyba by byla 0, což ovšem není pravda,\n",
    "protože by hodnoty vzorů musely ležet přímo na přímce. Tam ale neleží, což víme díky tomu, že každý\n",
    "oba vzorky jsou zatíženy nějakou chybou.\n",
    "\n",
    "Jako další vhodná operace se nabízí absolutní hodnota. Ta nám již odstraní případné\n",
    "odečtení chyby, nicméně jak posléze zjistíme, bude potřeba provést parciální derivace. Derivace\n",
    "mocniny je ovšem daleko jednoduší než derivace absolutní hodnoty. Dále, kvadratická chyba nám zajistí,\n",
    "že se hodnoty datasetu budou chovat, jako by byly rozmístěny dle normálního rozložení\n",
    "se středem v predikované hodnotě lineární funkce, což je náš předpoklad. Konečně, kvadratická\n",
    "funkce má pouze jedno lokální, resp. globální minimum.\n",
    "\n",
    "(Poznámka: Pokud bychom chtěli použít absolutní hodnotu, pracovali bychom s Lappplaceovým rozložení)\n",
    "\n",
    "\n",
    "Jak již bylo naznačeno, naším úkolem je nalézt globální minimmum z funkce $E(w_{0}, w_{1})$, tj.\n",
    "nalézt takové parametry  $w_{0}, w_{1}$, pro které bude bude suma všech čtverců chyb nejmenší.\n",
    "Z matematické analýzy víme, že se pokud hledáme globální minimum, tak je nutné nalézt\n",
    "parciální derivace funkce pode $w_{0}$ a $w_{1}$ a následně sestavit soustavu dvou rovnic\n",
    "o dovu neznámých.\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = 0 $\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = 0 $\n",
    "\n",
    "Vypočteme derivaci podle $w_{0}$ a vypočteme; analogicky určítem i $w_{1}$ .\n",
    "\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = ...  -2 (\\sum_{i=0}^N t_{i} - w_{0}(n+1) - w_{1} \\sum_{i=0}^N x_{i})$\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = \\sum_{i=0}^N 2(t_{i} - w_{0} - w_{1}x_{i})(-x_{i}) = -2 \\sum_{i=0}^N (t_{i}x_{i} - w_{0}x_{i} - w_{1}x_{i}^2)  $\n",
    "\n",
    "Výsledky paricálních derivací nyní dosadit do soustavy rovnic, a máme výslednou,\n",
    "tzn. <b>normální rovnici</b>.\n",
    "\n",
    "$ w_{0}(n+1) + w_{1}\\sum_{i=0}^N x_{i} = \\sum_{i=0}^N t_{i} $\n",
    "\n",
    "$ w_{0} \\sum_{i=0}^N x_{i} + w_{1} \\sum_{i=0}^N x_{i}^2 = \\sum_{i=0}^N x_{i}t_{i}$\n",
    "\n",
    "<br/>\n",
    "<li><b>Pomocí gradientího sestupu</b></li>\n",
    "\n",
    "Častější je ovšem využití gradientu. Gradient je vektor, který nám ukazuje, jakým směrem je\n",
    "derivace největší, tj. jakým směrem přímka nejrychleji stoupá. Pokud tento vektor otočíme o 90 stupňů,\n",
    "bude ukazovat kudy naše funkce nejrychleji klesá, a to je přesně co chceme. Z úvodu víme, že\n",
    "budeme hledat minimum v kvadratické funkci, která má minimum pouze jedno. To znamená, že se\n",
    "nemusíme obávat, že by jsme uvázli v lokálním minimu.\n",
    "\n",
    "Jedím z algoritmů pro nalezení takovéhoto minima je <i>Steepest Gradient Descent</i>. Tento\n",
    "algoritmus postupuje po krocích zvolené délky, a pro každý krok počítá nový gradient, tj. nový směr,\n",
    "kterým má postupovat. A kdy že se má alogritmus zastavit? Opět víme, že pokud je derivace\n",
    "nulová, může to znamenat hned několik věcí. Může se zde nacházet bod podezřelý z extrému, inflexní bod\n",
    "či lokální minimum. V každém případě to ovšem znamená, že daná funkce je zde\n",
    "rovnoběžná s osou <i>x</i>, a to implikuje jediné; našli jsme minimum funkce.\n",
    "\n",
    "\n",
    "\n",
    "Nevýhodou tohoto algoritmu je skutečnost, že pro výpočet každého gradientu je nutné projít\n",
    "celý dataset. Pokud náš dataset obsahuje 100 milionů záznamů, může to být trošku problém. V tomto\n",
    "případě lze zvolit jinou metodu, kupříkladu <i>Stochastic Gradient Descent</i>. Tato metoda počítá\n",
    "gradient z jednoho, náhodně výbraného vzorku. Její postup samozřejmě není tolik přímočarý\n",
    "jako v případě  <i>Steepest Gradient Descent</i>, ovšem není tolik náročný.\n",
    "\n",
    "\n",
    "![SegmentLocal](images/gradient.gif \"segment\")\n",
    "\n",
    "<li><b>Jiný způsob odvození</b></li>\n",
    "\n",
    "Posledním, ovšem nejvíce sofistikovaným způsobem je využít operací nad maticemi a vektory, pomocí\n",
    "kterých lze dojít k výsledku během jednoho kroku. To znamená, že nad naší vstupní rovnicí provedeme\n",
    "několik maticových operací, jejiž výsledkem budou optimální parametry $w_{0}$ a $w_{1}$.\n",
    "\n",
    "Nejdříve začneme tím, že si rovnici můžeme přepsat do skalárního součinu.\n",
    "\n",
    "$y = w_{1}x + w_{0} =  \\hat x^Tw $ , kde\n",
    "\n",
    "$ \\mathbf{\\hat x}= \\begin{bmatrix}1 \\\\\n",
    "x\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$ \\mathbf{w}= \\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Můžeme něco takového udělat? Samozřejmě, protože násobíme transponovaný sloupcpvý vektor, tj. řádkový\n",
    "s sloupcovým vektorem. Tzn. máme operaci\n",
    "$\\begin{bmatrix}1 \\space\n",
    "x\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix} = 1 w_{0} + xw_{1} = w_{1}x + w_{0} = y$\n",
    "\n",
    "\n",
    "Vzorec pro objektivní funkci je opět stejný, nicméně pro další odovozování použijeme\n",
    "notaci skalárního součinu a přidáme vynásobení konstantou. Tato konstanta nás nijak netrápí,\n",
    "na nalezení minima či maxima to nemá žádný vliv.\n",
    "\n",
    "$ E(w0, w1) = \\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 =\\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w} )^2$\n",
    "\n",
    "Nyní si naši funkci dvou proměnných $ E(w0, w1)$ můžeme přepsat jako funkci\n",
    " vektoru $ E( \\mathbf{w})$. Nebude nyní derivovat podle dvou proměnných, ale podle vektoru.\n",
    " Výstupem této funkce je opět nám již známý gradient.\n",
    "\n",
    "\n",
    "\n",
    " $ \\frac{\\partial}{\\partial\\mathbf{w}}E(\\mathbf{w}) =\n",
    " \\frac{\\partial}{\\partial\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    " $\n",
    "\n",
    "\n",
    " Poznámka: Gradient se dá ekvivalentně zapsat jako\n",
    " $ \\triangledown_{\\mathbf{w}} E(\\mathbf{w}) =\n",
    " \\frac{\\partial E (\\mathbf{w})}{\\partial \\mathbf{w}} =\n",
    "  \\begin{bmatrix} \\frac{\\partial E (\\mathbf{w})}{\\partial w_{0}} \\\\\n",
    "    \\frac{\\partial E (\\mathbf{w})}{\\partial w_{1}}\n",
    "    \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "\n",
    "V následujícím kroku jsme si akorát konstantu vytkly před sumu, s tím že derivace sumy je suma derivací.\n",
    "\n",
    "$\n",
    "= \\frac{1}{2}  \\sum_{n=1}^N \\frac{\\partial}{\\partial\\mathbf{w}} (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    "$\n",
    "\n",
    "Nyní naši objektivní funkci zderivujeme podle vektoru $ \\mathbf{w}$. Funkci derviuje klasicky jako složenou funkci,\n",
    "tj. druhou mocninu dám před funkci, zde se nám krásně vykrátí s naší konstantou a následně vynásobíme\n",
    "vnitřní složkou funkce\n",
    "\n",
    "\n",
    "$\n",
    "= \\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w}) \\frac{\\partial}{\\partial\\mathbf{w}}\n",
    "\\color{#f05454}{(t_{n} - \\hat x_{n}^T \\mathbf{w})}\n",
    "$\n",
    "\n",
    "\n",
    " Nyní nám zbýva zderivovat právě onu vnitřní složku funkce (červená část ). Když se na tuto část podíváme,\n",
    " zjistíme že první složka závorky  ($t_{n}$) je konstanta, tzn. ať už budeme derivovat podle čehokoliv,\n",
    " vždy to bude 0. Nás tedy bude zajímat druhá část závorky, kde je skalární součin vektoru, který budeme\n",
    " chtít derivovat podle vektoru $\\mathbf{w}$, což je vlastně parciální derivace podle\n",
    " jeho složek, tj. $w_{0}$ a $w_{1}$.\n",
    "\n",
    " Nyní si to více rozepíšeme. Potřebujeme tedy vypočítat derivaci druhé části červené závorky, což je:\n",
    "\n",
    "\n",
    " $\n",
    "  \\frac{\\partial}{\\partial \\mathbf{w}} \\mathbf{\\hat x}_{n}^T \\mathbf{w} =\n",
    "  $\n",
    "\n",
    "  $ =\\frac{\\partial}{\\partial \\mathbf{w}} \\begin{bmatrix}w_{0}x_{0} + \\space\n",
    "w_{1}x_{1}\n",
    "\\end{bmatrix}\n",
    " $\n",
    "\n",
    " Nyní máme rozepsaný skalární součin vektorů. Když ho zderivujeme podle $w_{0}$, dostaname $x_{0}$,\n",
    " když ho zderivujeme podle $w_{1}$, dostaneme $x_{1}$. To znamená, že derivace celé závorky je\n",
    " $\\mathbf{\\hat x}$, takže to tak můžeme přepsat i v červené části rovnice.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w})\n",
    "\\color{#f05454}{\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "\n",
    "Aktuálně máme furt stejnou rovnici, která nám počítá gradient, akorát mírně upravenou. Nyní celou závorku\n",
    "vynásobíme vektorem $\\mathbf{\\hat x}$ (červeně), takže nám vzniknou dvě sumy. Dále, výraz položíme rovno\n",
    "0, protože nás samozřejmě zajímá, kde je gradient rovný 0, tzn. kde je minimum funkce.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N t_{n}\n",
    "\\mathbf{\\hat x_{n}} - \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{ \\hat x}_{n}^T \\mathbf{w} = 0\n",
    "$\n",
    "\n",
    "Naším posledním větším krokem bude vytknout si $\\mathbf{w}$, což je vektor koeficientů $w_{0}$ a\n",
    "$w_{1}$. Nyní si první sumu si převedeme na pravou stranu rovnice.\n",
    "\n",
    "$\n",
    "\\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n} \\mathbf{w} = \\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}\n",
    "$\n",
    "\n",
    "\n",
    "Dále můžeme z levé strany rovnice oddělit $\\mathbf{w}$ od zbytku výrazu, protože $\\mathbf{w}$ nemá index sumy,\n",
    "tzn. na ní nezáleží.\n",
    "\n",
    "$\n",
    "\\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})}  \\mathbf{w} = \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "Nyní chcem dostat samotné $\\mathbf{w}$. To znamená, že celou rovnici musíme podělit červeným výrazem. Když si\n",
    "uvědomíme, že červený výraz je ve skutečnosti násobení sloupcového vektoru řádkovým, tzn. výsledek je matice\n",
    "2x2, tak zjistíme, že potřebujeme celou rovnici podělit maticí 2x2. Toho docílíme tak, že zleva k celé rovnici\n",
    "přínásobíme její inverzní matici. Na levé straně rovnice tedy zůstane samotné $\\mathbf{w}$, protože pokud\n",
    "matici vynásobíme její inverzní maticí, dostaneme jednotkovou matici.\n",
    "\n",
    "$\n",
    "\\mathbf{w} = \\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})^{-1}} \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "A máme řešení! Pokud hodnoty vektoru $\\mathbf{w}$, tj. $w_{0}$ a $w_{1}$ nastavíme na hodnoty, které nám vrátí\n",
    "naše pravá strana rovnice, máme naše hledané parametry. Tento tvar ovšem není moc pěkný, protože pokud bychom to chtěli,\n",
    "implementovat, tak budeme muset pro červenou část rovnice  vytvořit for cyklus a vynásobit všechny složky vektoru $\\mathbf{\\hat x} $ s\n",
    "$\\mathbf{\\hat x^T} $ a následně vše sečíst. Obdobně bychom to museli udělat pro zelenou část rovnice. Nicméně my si můžeme\n",
    "vytvořit matici $\\mathbf{\\hat X} $, která bude obsahovat jako sloupce naše vektory $\\mathbf{\\hat x} $. Dále si také\n",
    "vytvoříme vektor našich hodnot datasetu, $\\mathbf{t} $.\n",
    "\n",
    "$\\mathbf{\\hat X} = [\\hat x_{1}, \\hat x_{2}, \\hat x_{3},..., \\hat x_{N}] $\n",
    "\n",
    "\n",
    "$\\mathbf{t} = [t_{1}, t_{2},  t_{3},..., t_{N}] $\n",
    "\n",
    "\n",
    "Červenou část rovnice nyní můžeme přepsat na součin matice $\\mathbf{X}$ s její  transponzicí, obdobně u zelené části.\n",
    "\n",
    "$\n",
    "\\mathbf{w} = \\color{#f05454}{(\\mathbf{\\hat X}  \\mathbf{\\hat X}^T)^{-1}} \\color{#59886b}{\\mathbf{\\hat X}\\mathbf{t}}\n",
    "$\n",
    "\n",
    "Nyní máme analytické řešení, které se skládá pouze z násobení maticemi, tzn. je lehce naprogramovatelné.\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lineární regrese\n",
    "Původ lineární regrese je založen na regresi k průměru.\n",
    "\n",
    "* *Jak to, že děti vysokých rodičů samy bývají vysoké, ale ne tak jako jejich rodiče?*\n",
    "\n",
    "#### Jednoduchá lineární regrese\n",
    "<img src=\"images/weight-height.jpg\" alt=\"weight-heigh\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahující záznamy o pohlaví-výška-váha\n",
    "Zdroj: https://www.kaggle.com/mustafaali96/weight-height\n",
    "\"\"\"\n",
    "\n",
    "wh_df = pd.read_csv('data/weight-height.csv')\n",
    "wh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Příklad jednoduché regresivní analýzy (pouze jeden regres)\n",
    "Z tohoto důvodu budeme zkoumat pouze muže a sloupec pohlaví můžeme ignorovat.\n",
    "Dále si převedeme hodnoty z datasetu na metrické jednotky, neboť jsou uvedeny v imperiálních hodnotách.\n",
    "\"\"\"\n",
    "\n",
    "# 1 palec = 2,54 cm\n",
    "height_constant = 2.54\n",
    "\n",
    "# 1 libra = 0,45359237 kg\n",
    "weight_constant = 0.4535923\n",
    "\n",
    "males_only_df = (wh_df[(wh_df.Gender == 'Male')]).drop('Gender',1) #\n",
    "males_only_df.Height *= height_constant\n",
    "males_only_df.Weight *= weight_constant\n",
    "males_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males_only_df.plot.scatter(x=\"Height\", y=\"Weight\", color='b', title='Height x Weight [Males only]', s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ověření lineární korelační závislosti\n",
    "\n",
    "p - Pearsonův korelační koeficient měří sílu lineární závislosti mezi dvěma veličinami.\n",
    "\n",
    "OTÁZKA - Jakých hodnot může p nabývat?\n",
    "\"\"\"\n",
    "x = males_only_df.Height\n",
    "y = males_only_df.Weight\n",
    "p = stats.pearsonr(x, y)\n",
    "print(f\"Hodnota Pearsonova korelačního koeficientu: {p[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape((-1, 1)), y)\n",
    "# print(model.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"blue\", s=2)\n",
    "plt.plot(x, model.predict(x.values.reshape((-1, 1))), color = \"red\")\n",
    "plt.title(\"Male weight prediction\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"blue\", s=2)\n",
    "plt.plot(x, model.predict(x.values.reshape((-1, 1))), color = \"red\")\n",
    "plt.title(\"Male weight prediction\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = input('Zadejte vaši výšku: ')\n",
    "weight_predict = model.predict(np.array(float(input_height)).reshape((-1, 1)))[0]\n",
    "print(f\"Predikovaná váha dle jednoduché lineární regresivní analýzy: {np.round(weight_predict, 2)}kg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vícenásobná lineární regrese\n",
    "\n",
    "V reálném světě je výstup často ovlivněn více než jedním faktorem (regresem).\n",
    "\n",
    "$ y = f(x) = w_{0} + w_{1}x_{1} + w_{2}x_{2} + ... + w_{n}x_{n}  $\n",
    "<img src=\"images/fuel.png\" alt=\"fuel\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahuje záznamy kolik mil je daný automobil schopen ujet na jeden galon\n",
    "včetně dodatečných parametrů jako objem motoru, zrychlení etc.\n",
    "\"\"\"\n",
    "\n",
    "#MPG = Počet ujetých mil na jeden Galon (3,785 litru) -> Vyšší je lepší\n",
    "toLitres = lambda x : 235.214583 / x\n",
    "\n",
    "column_names = ['mpg', 'horsepower', 'weight', 'acceleration','displacement']\n",
    "\n",
    "cubic_inch_constant = 16.387064\n",
    "\n",
    "cars_df = pd.read_csv('data/auto-mpg.csv', usecols=column_names, na_values='?')\n",
    "cars_df.weight *= weight_constant\n",
    "cars_df.displacement *= cubic_inch_constant\n",
    "cars_df.dropna()\n",
    "\n",
    "cars_df.horsepower =  cars_df.horsepower.astype('float')\n",
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1 = stats.pearsonr(cars_df['mpg'], cars_df['horsepower'])[0]\n",
    "p2 = stats.pearsonr(cars_df['mpg'], cars_df['weight'])[0]\n",
    "p3 = stats.pearsonr(cars_df['mpg'], cars_df['acceleration'])[0]\n",
    "p4 = stats.pearsonr(cars_df['mpg'], cars_df['displacement'])[0]\n",
    "\n",
    "print(f\"Míra lineární závislosti spotřeba x počet koní: {p1}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x hmotnost: {p2}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zrychlení: {p3}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zdvihový objem: {p4}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars_df.plot.scatter(x='horsepower', y='mpg', color='r', title='MPG x Horsepower')\n",
    "cars_df.plot.scatter(x='weight', y='mpg', color='b', title='MPG x Weight')\n",
    "cars_df.plot.scatter(x='acceleration', y='mpg', color='g', title='MPG x Acceleration')\n",
    "cars_df.plot.scatter(x='displacement', y='mpg', color='m', title='MPG x Zdvihový objem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "second_model_x = cars_df[['horsepower', 'acceleration', 'weight', 'displacement']]\n",
    "second_model_y = cars_df['mpg']\n",
    "\n",
    "# V datasetu jsou často výkonná auta u sebe, proto použijeme určitý pseudonáhodný pick\n",
    "seed = random.randint(0, 1000)\n",
    "\n",
    "second_model_x_train, second_model_x_test, \\\n",
    "second_model_y_train, second_model_y_test = train_test_split\\\n",
    "(second_model_x, second_model_y,test_size=0.25,random_state=seed)\n",
    "\n",
    "second_model.fit(second_model_x_train, second_model_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST přesnosti modelu\n",
    "\n",
    "accuracy = np.round(second_model.score(second_model_x_test, second_model_y_test), 4) * 100\n",
    "print(f'Přesnost modelu: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikce spotřeby jiného staršího vozidla - použijeme Škodu 120\n",
    "# Zdroj: http://skodaps.wz.cz/S105-136_technicke_1.php\n",
    "\n",
    "# Nutné brát v potaz, že mnoho aut v datasetu jsou auta americká\n",
    "\n",
    "s120_horsepower = 53.0\n",
    "s120_acceleration = 20.0\n",
    "s120_weight = 890.0\n",
    "s120_displacement = 1147.0\n",
    "\n",
    "s120_stats = np.array([s120_horsepower,s120_acceleration, s120_weight, s120_displacement])\n",
    "result = second_model.predict(s120_stats.reshape(1, -1))[0]\n",
    "print(\"Predikovaná spotřeba vozu Škoda 120 pomocí vícenásobné lineární regresivní analýzy: {}l/100km.\".\\\n",
    "      format(np.round(toLitres(result), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomiální regrese\n",
    "\n",
    "Nyní si můžeme říct, že né všechny data se dají napasovat na lineární funkci, tzn. někdy je třeba\n",
    "aproximovat data polynomem. My se nyní naučíme aproximovat jakkoliv složitou funkci. Abychom\n",
    "tuto funkci ovšem mohli vytvořit, je nutné ji poskládat z jednodušších funkcí. Tyto funkce mohou\n",
    "být kupříkladu polynomy, obecně vzato to mohou být jakkékoliv nelineární funkce. Uvažujme například polynomy\n",
    "zobrazené na následujícím obrázku.\n",
    "![image info](images/polynomials.png)\n",
    "\n",
    "\n",
    "Když vytvoříme jejich linární kombinaci, může nám vzniknout například polynom zobrazený na následujícím obrázku.\n",
    "Vidíme tedy, že poměrně složitou funkci lze vytvořit složením funkcí jednodušších. Naším úkolem bude nyní\n",
    "hledat koeficienty polynomiální funkce tak, aby výsledná funkce co nejlépe aproximovala náš soubor dat.\n",
    "\n",
    "![image info](images/polynomial.png)\n",
    "\n",
    "\n",
    "Zde si můžeme opět vytvořit vektory $\\mathbf{\\hat x}$ a $\\mathbf{w}$ podobně, jako tomu bylo u lineární\n",
    "regrese. Nnyí ovšem tyto vektory nebudou dvojrozměrné, ale obecne K-rozměrné.\n",
    "\n",
    "$\n",
    "\\mathbf{\\hat x} =\n",
    "\\begin{bmatrix}1\\\\\n",
    "x\\\\\n",
    "x^2\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "x^K\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{w} =\n",
    "\\begin{bmatrix}w_{0}\\\\\n",
    "w_{1}\\\\\n",
    "w_{2}\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "w_{K}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Nyní úplně stejně jako při linární regresi, vytvoříme obecný předpis pro polynomiální funkci.\n",
    "\n",
    "$\n",
    "y = \\mathbf{\\hat x^T w} = w_{0} + w_{1}x + w_{2}x^2 + w_{3}x^3 + ... + w_{K}x^K\n",
    "$\n",
    "\n",
    "Pokud se podíváme pouze na první dva členy této funkce, zjistíme, že je to vlastně vzorec pro lineární regresi.\n",
    "Lineární regrese je tedy speciálním případem polynomiální regrese pro K=1.\n",
    "\n",
    "##### Polynomiální regrese příklad COVID-19\n",
    "<img src=\"images/covid.png\" alt=\"fuel\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "\n",
    "import time\n",
    "order = 15\n",
    "\n",
    "for k in range(order):\n",
    "\n",
    "\n",
    "    mymodel = np.poly1d(np.polyfit(x, y, k))\n",
    "    plt.scatter(x, y, color='red', s=20)\n",
    "    myline = np.linspace(1, 22, 100)\n",
    "\n",
    "    plt.plot(myline, mymodel(myline))\n",
    "    plt.show()\n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predikce covid-19\n",
    "\n",
    "cols = ['country', 'cases', 'date', 'deaths', 'Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
    "\n",
    "covid_csv = pd.read_csv('data/covid_dataset.csv', iterator=True, usecols=cols)\n",
    "\n",
    "covid_df = pd.concat([chunk[chunk['country'] == 'Czechia'] for chunk in covid_csv])\n",
    "\n",
    "covid_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every nth row and reverse dataset, so the newest values will be on the right side of plot\n",
    "import datetime as dt\n",
    "covid_df = covid_df.head(90).iloc[::-1]\n",
    "\n",
    "\n",
    "date = covid_df['date']\n",
    "cases = covid_df['cases']\n",
    "deaths = covid_df['deaths']\n",
    "cummulative = covid_df['Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
    "\n",
    "\n",
    "# plt.xlabel('Covid-19 data in last 90 days', fontsize=15)\n",
    "plt.scatter(cummulative, deaths, s=10, color='red')\n",
    "\n",
    "\n",
    "plt.xlabel('cumulative cases for 14 days per 100k', fontsize=13)\n",
    "plt.ylabel('number of deaths', fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def find_best_order():\n",
    "    X_train_covid, X_test_covid, y_train_covid, y_test_covid = train_test_split(cummulative, deaths, test_size=0.2, random_state=0)\n",
    "    val = -1\n",
    "    order = 0\n",
    "    for k in range(1,10):\n",
    "        covid_model = np.poly1d(np.polyfit(X_train_covid, y_train_covid, k))\n",
    "        score = np.round(r2_score(y_test_covid, covid_model(X_test_covid)), 3)\n",
    "        print(\"actual best value {} and score {} and order {}\".format(val, score, k))\n",
    "        if score > val:\n",
    "            val = score\n",
    "            order = k\n",
    "\n",
    "    print(\"final order: {}\".format(order))\n",
    "    final_model = np.poly1d(np.polyfit(X_train_covid, y_train_covid, order))\n",
    "    print(\"R2 score is : {}\".format(r2_score(y_test_covid, covid_model(X_test_covid))))\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(cummulative, deaths, s=10, color='red')\n",
    "plt.xlabel('cumulative cases for 14 days per 100k', fontsize=13)\n",
    "plt.ylabel('number of deaths', fontsize=13)\n",
    "\n",
    "covid_model = find_best_order()\n",
    "covid_line = np.linspace(0, 1700, 300)\n",
    "\n",
    "plt.plot(covid_line, covid_model(covid_line))\n",
    "plt.show()\n",
    "\n",
    "# print(\"R2 score is: {}\".format(np.round(r2_score(y_test_covid, covid_model(X_test_covid), 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_input = 1700\n",
    "predicted_values = covid_model(predicted_input)\n",
    "\n",
    "print(\"Predikovany pocet umrti pri kumulativni nakaze {} lidi za 14 dni je {} umrti\".format(predicted_input, np.round(predicted_values, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistická regrese\n",
    "Logistická regrese je ač se to nemusí na první pohled zdát metodou klasifikace. Při regresi\n",
    "jsme měli nějaká vstupní data, a na jejichž základě jsme se snažili predikovat nějakou funkci.\n",
    "Náš výstup byl tedy spojitý.\n",
    "\n",
    "#### Logistická regrese - Titanic\n",
    "<img src=\"images/titanic-meme.jpg\" alt=\"fuel\" width=\"350\" margin-bottom=\"20\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('data/titanic-dataset.csv')\n",
    "titanic_data = titanic_data.drop(columns = ['Name'])\n",
    "titanic_data['Fare'] = titanic_data['Fare'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Survived',data=titanic_data)\n",
    "plt.title('Titanic - přeživší [přežil x nepřežil]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Převod vybraných informací na pravdivostní hodnoty\n",
    "final_data = pd.get_dummies(titanic_data, columns =['Sex','Pclass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.loc[:,final_data.columns != 'Survived']\n",
    "y = final_data.loc[:,final_data.columns == 'Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Vyrovnání vzorků (počet přeživších/zemřelých)\n",
    "smt = SMOTE(random_state=0)\n",
    "\n",
    "data_X,data_y=smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Přesnost modelu logistické regrese: 78.83 %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(max_iter=750)\n",
    "logistic_reg.fit(data_X, np.array(data_y).reshape(-1, 1))\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "print(f'Přesnost modelu logistické regrese: {np.round(logistic_reg.score(X_test, y_test) *100, 2)} %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](images/CFmatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f6692ae3e50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logistic_reg, X_test, y_test, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, logistic_reg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logistic_reg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r-')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](images/ROC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zadejte pohlaví [M - muž, F - žena]: M\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Titanic - predikce přežití určitého pasažéra\n",
    "\n",
    "\n",
    "Cena lístků: Ticket Prices for the Titanic when she sailed on her maiden voyage \n",
    "in 1912: First Class Suite- £870 or $4,350. First Class Berth- £30 or $150.\n",
    "Second Class- £12 or $60.\n",
    "\n",
    "Na čem záviselo přežití: \n",
    "https://zoommagazin.iprima.cz/nejvetsi-katastrofy/prezili-byste-ztroskotani-titaniku-zname-vase-sance\n",
    "\"\"\"\n",
    "\n",
    "def predictSurvive(sex, age, p_class, parrents_childs, siblings, fare):\n",
    "    sex_male = True if sex == 'M' else False\n",
    "    if p_class == 1:\n",
    "        p_class_2 = False\n",
    "        p_class_3 = False\n",
    "    elif p_class == 2:\n",
    "        p_class_2 = True\n",
    "        p_class_3 = False\n",
    "    else:\n",
    "        p_class_2 = False\n",
    "        p_class_3 = True\n",
    "        \n",
    "\n",
    "    passsager = np.array([age, siblings, parrents_childs, fare, sex_male, p_class_2, p_class_3])\n",
    "    prediction = logistic_reg.predict(passsager.reshape(1, -1))\n",
    "    pst_died, pst_survived = logistic_reg.predict_proba(passsager.reshape(1, -1))[0]\n",
    "    if prediction:\n",
    "        print(\"Pravděpodobně by jste přežil s pravděpodobností {} %.\".format(np.round(pst_survived * 100, 2)))\n",
    "    else:\n",
    "        print(\"Pravděpodobně by jste zemřel s pravděpodobností {} %.\".format(np.round(pst_died * 100, 2)))\n",
    "\n",
    "sex = input('Zadejte pohlaví [M - muž, F - žena]: ')\n",
    "age = int(input('Zadejte věk: '))\n",
    "p_class = int(input('Zadejte třídu [1 - 3]: '))\n",
    "p_c_count = int(input('Zadejte počet rodičů/dětí na palubě: '))\n",
    "s_count = int(input('Zadejte počet sourozenců na palubě: '))\n",
    "fare = int(input('Zadejte cenu lístku [£]: '))\n",
    "\n",
    "predictSurvive(sex, age, p_class, p_c_count, s_count, fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "\n",
    "Pomocí rozhodovacích stromů lze vytvářet regresní modely formou stromových struktur. Regresní analýza pomocí rozhodovacích rozbije náš dataset na menší a menší podmnožiny.\n",
    "\n",
    "\n",
    "\n",
    "Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node (e.g., Outlook) has two or more branches (e.g., Sunny, Overcast and Rainy), each representing values for the attribute tested. Leaf node (e.g., Hours Played) represents a decision on the numerical target. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.\n",
    "\n",
    "<img src=\"images/1a.png\" alt=\"Decision Tree Regression\" width=\"600\"/>\n",
    "Důležité je též zajistit, aby se model neučil ze šumu.\n",
    "<img src=\"images/DF.png\" alt=\"Decision Tree Regression\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n",
    "Metoda učení s učitelem používaná zejména na klasifikaci, ale možnost užít i na regresivní analýzu. Je použita technika, která kombinuje předpovědi z více algoritmů ML a vytváří tím přesnější předpověď.\n",
    "* Regresní les sestává z několika regresních stromů a výsledná regresní funkce je obvykle definována jako vážený průměr regresních funkcí jednotlivých stromů.\n",
    "\n",
    "\n",
    "<img src=\"images/randomForest.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    - Příklad dopočítání chybějících hodnot měny Bitcoin\n",
    "    - Silně závisí na tom kolik máme dat, respektive vzdálenost vzorků\n",
    "\"\"\"\n",
    "\n",
    "# Načtení zkoumaných dat\n",
    "column_names = ['Unix Timestamp', 'Date', 'Open']\n",
    "btc_df = pd.read_csv('data/btc-dataset.csv', usecols=column_names)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "btc_df.plot.scatter(x=\"Unix Timestamp\", y=\"Open\", color='gold', title='Bitcoin value evolution');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_sample = int(input(\"Zadejte vzdálenost vzorků ve dnech: \"))\n",
    "\n",
    "X = (btc_df.iloc[::days_per_sample, 0].values).reshape(-1, 1)\n",
    "y = btc_df.iloc[::days_per_sample, 2].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.45)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_prediction = regressor.predict(X_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "plt.plot(btc_df['Unix Timestamp'], btc_df['Open'],color = 'gold')\n",
    "plt.plot(X_test, test_values_prediction,'ro',  color = 'blue')\n",
    "\n",
    "print(f\"Přesnost random forest modelu {np.round(regressor.score(X_test, y_test) * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda podpůrných vektorů\n",
    "\n",
    "Opět metoda učení s učitelem, která se používá zejména v klasifikaci, ale může nalézt využití i v regresivní analýze. Typickým použitím je predikce vývoje měn či akcií.\n",
    "SVM regrese využívá necitlivou ztrátovou funkci - pokud je chyba menší než *Epsilon*, není to považováno za chybu.\n",
    "\n",
    "* Duální Lagrangeova funkce, jádrová transformace (kernel)\n",
    "* Alterinativa pro neuronové sítě\n",
    "* Správná funkce SVM z velké části záleží na vhodné volbě jádrové funkce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Epsilon-Support Vector Regression\n",
    "\"\"\"\n",
    "\n",
    "PREDICT_SIZE = int(input('Zadejte požadovanou délku predikce [v dnech]: '))\n",
    "HISTORY_LEN = int(input('Zadejte požadovanou délku uvažované historie kterou chcete při predikci uvažovat [v dnech]: '))\n",
    "\n",
    "# Příprava a úprava dat\n",
    "df = pd.read_csv('data/btc-dataset.csv', usecols=['Open']).head(HISTORY_LEN)\n",
    "prediction_days = PREDICT_SIZE\n",
    "df['Prediction'] = df['Open'].shift(-prediction_days)\n",
    "yvm = np.array(df.drop(['Prediction'],1))\n",
    "yvm = yvm[:len(df)-prediction_days]\n",
    "Xvm = np.array(df['Prediction'])  \n",
    "Xvm = Xvm[:-prediction_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.randint(0, 1000)\n",
    "\n",
    "#xvm_train, xvm_test, yvm_train, yvm_test = train_test_split(Xvm, yvm, test_size=0.15, random_state=seed)\n",
    "xvm_train = Xvm\n",
    "yvm_train = yvm\n",
    "prediction_days_array = np.array(df.drop(['Prediction'],1))\n",
    "prediction_days_array = prediction_days_array[:prediction_days]\n",
    "svr_rbf = SVR(kernel='rbf',C=1000,epsilon = 0.001)\n",
    "svr_rbf.fit(xvm_train.reshape(-1,1), yvm_train)\n",
    "\n",
    "#print(f\"Vectorová regrese přenost modelu: {np.round(svr_rbf.score(xvm_test, yvm_test),4) * 100} %.\", )\n",
    "\n",
    "\n",
    "svm_prediction = svr_rbf.predict(prediction_days_array)\n",
    "\n",
    "plt.plot(range(1, PREDICT_SIZE + 1), svm_prediction ,color = 'green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
